{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:\\\\Nikhil\\\\VScode\\\\ML\\\\datasets&models\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(path + \"Gpt&human_data.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24322, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>human_answers</th>\n",
       "      <th>chatgpt_answers</th>\n",
       "      <th>index</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why is every book I hear about a \" NY Times # ...</td>\n",
       "      <td>[Basically there are many categories of \" Best...</td>\n",
       "      <td>[There are many different best seller lists th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reddit_eli5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If salt is so bad for cars , why do we use it ...</td>\n",
       "      <td>[salt is good for not dying in car crashes and...</td>\n",
       "      <td>[Salt is used on roads to help melt ice and sn...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reddit_eli5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do we still have SD TV channels when HD lo...</td>\n",
       "      <td>[The way it works is that old TV stations got ...</td>\n",
       "      <td>[There are a few reasons why we still have SD ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reddit_eli5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why has nobody assassinated Kim Jong - un He i...</td>\n",
       "      <td>[You ca n't just go around assassinating the l...</td>\n",
       "      <td>[It is generally not acceptable or ethical to ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reddit_eli5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How was airplane technology able to advance so...</td>\n",
       "      <td>[Wanting to kill the shit out of Germans drive...</td>\n",
       "      <td>[After the Wright Brothers made the first powe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reddit_eli5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Why is every book I hear about a \" NY Times # ...   \n",
       "1  If salt is so bad for cars , why do we use it ...   \n",
       "2  Why do we still have SD TV channels when HD lo...   \n",
       "3  Why has nobody assassinated Kim Jong - un He i...   \n",
       "4  How was airplane technology able to advance so...   \n",
       "\n",
       "                                       human_answers  \\\n",
       "0  [Basically there are many categories of \" Best...   \n",
       "1  [salt is good for not dying in car crashes and...   \n",
       "2  [The way it works is that old TV stations got ...   \n",
       "3  [You ca n't just go around assassinating the l...   \n",
       "4  [Wanting to kill the shit out of Germans drive...   \n",
       "\n",
       "                                     chatgpt_answers  index       source  \n",
       "0  [There are many different best seller lists th...    NaN  reddit_eli5  \n",
       "1  [Salt is used on roads to help melt ice and sn...    NaN  reddit_eli5  \n",
       "2  [There are a few reasons why we still have SD ...    NaN  reddit_eli5  \n",
       "3  [It is generally not acceptable or ethical to ...    NaN  reddit_eli5  \n",
       "4  [After the Wright Brothers made the first powe...    NaN  reddit_eli5  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>human_answers</th>\n",
       "      <th>chatgpt_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why is every book I hear about a \" NY Times # ...</td>\n",
       "      <td>[Basically there are many categories of \" Best...</td>\n",
       "      <td>[There are many different best seller lists th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If salt is so bad for cars , why do we use it ...</td>\n",
       "      <td>[salt is good for not dying in car crashes and...</td>\n",
       "      <td>[Salt is used on roads to help melt ice and sn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do we still have SD TV channels when HD lo...</td>\n",
       "      <td>[The way it works is that old TV stations got ...</td>\n",
       "      <td>[There are a few reasons why we still have SD ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why has nobody assassinated Kim Jong - un He i...</td>\n",
       "      <td>[You ca n't just go around assassinating the l...</td>\n",
       "      <td>[It is generally not acceptable or ethical to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How was airplane technology able to advance so...</td>\n",
       "      <td>[Wanting to kill the shit out of Germans drive...</td>\n",
       "      <td>[After the Wright Brothers made the first powe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Why is every book I hear about a \" NY Times # ...   \n",
       "1  If salt is so bad for cars , why do we use it ...   \n",
       "2  Why do we still have SD TV channels when HD lo...   \n",
       "3  Why has nobody assassinated Kim Jong - un He i...   \n",
       "4  How was airplane technology able to advance so...   \n",
       "\n",
       "                                       human_answers  \\\n",
       "0  [Basically there are many categories of \" Best...   \n",
       "1  [salt is good for not dying in car crashes and...   \n",
       "2  [The way it works is that old TV stations got ...   \n",
       "3  [You ca n't just go around assassinating the l...   \n",
       "4  [Wanting to kill the shit out of Germans drive...   \n",
       "\n",
       "                                     chatgpt_answers  \n",
       "0  [There are many different best seller lists th...  \n",
       "1  [Salt is used on roads to help melt ice and sn...  \n",
       "2  [There are a few reasons why we still have SD ...  \n",
       "3  [It is generally not acceptable or ethical to ...  \n",
       "4  [After the Wright Brothers made the first powe...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop([\"index\",\"source\"],axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df[\"chatgpt_answers\"].isna().sum())\n",
    "print(df[\"human_answers\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Basically there are many categories of \" Best Seller \" . Replace \" Best Seller \" by something like \" Oscars \" and every \" best seller \" book is basically an \" oscar - winning \" book . May not have won the \" Best film \" , but even if you won the best director or best script , you \\'re still an \" oscar - winning \" film . Same thing for best sellers . Also , IIRC the rankings change every week or something like that . Some you might not be best seller one week , but you may be the next week . I guess even if you do n\\'t stay there for long , you still achieved the status . Hence , # 1 best seller .',\n",
       " \"If you 're hearing about it , it 's because it was a very good or very well - publicized book ( or both ) , and almost every good or well - publicized book will be # 1 on the NY Times bestseller list for at least a little bit . Kindof like how almost every big or good movies are # 1 at the box office on their opening weekend .\",\n",
       " \"One reason is lots of catagories . However , how the NY Times calculates its best seller list is n't comprehensive , and is pretty well understood by publishers . So publishers can [ buy a few books ] ( URL_0 ) in the right bookstores and send a book to the top of the list for at least a week .\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"human_answers\"][:1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There are many different best seller lists that are published by various organizations, and the New York Times is just one of them. The New York Times best seller list is a weekly list that ranks the best-selling books in the United States based on sales data from a number of different retailers. The list is published in the New York Times newspaper and is widely considered to be one of the most influential best seller lists in the book industry. \\nIt\\'s important to note that the New York Times best seller list is not the only best seller list out there, and there are many other lists that rank the top-selling books in different categories or in different countries. So it\\'s possible that a book could be a best seller on one list but not on another. \\nAdditionally, the term \"best seller\" is often used more broadly to refer to any book that is selling well, regardless of whether it is on a specific best seller list or not. So it\\'s possible that you may hear about a book being a \"best seller\" even if it is not specifically ranked as a number one best seller on the New York Times list or any other list.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df[\"chatgpt_answers\"][:1][0]\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    data = str(data)\n",
    "    data = data.lower()\n",
    "    data = re.sub(r\"[^0-9a-zA-Z]\", \" \",data)\n",
    "    data = re.sub(r\" +\", \" \", data)\n",
    "    data = data.strip()\n",
    "\n",
    "    filtered_token =[]\n",
    "    doc = nlp(data)\n",
    "    for token in doc:\n",
    "        if token is token.is_punct or token.is_stop:\n",
    "            continue\n",
    "        filtered_token.append(token.lemma_)\n",
    "\n",
    "    return \" \".join(filtered_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'different good seller list publish organization new york times new york times good seller list weekly list rank good selling book united states base sale datum number different retailer list publish new york times newspaper widely consider influential good seller list book industry nit s important note new york times good seller list good seller list list rank sell book different category different country s possible book good seller list nadditionally term good seller broadly refer book sell regardless specific good seller list s possible hear book good seller specifically rank number good seller new york times list list'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(str(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24322,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"chatgpt_answers\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df[\"cleaned_gpt_ans\"] = df[\"chatgpt_answers\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 25min 4s\n",
      "Wall time: 35min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df[\"cleaned_human_ans\"] = df[\"human_answers\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cleaned_gpt_ans\"] = \"__label__AIGenerated\" + \" \" + df[\"cleaned_gpt_ans\"]\n",
    "df[\"cleaned_human_ans\"] = \"__label__HumanWritten\" + \" \" + df[\"cleaned_human_ans\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>human_answers</th>\n",
       "      <th>chatgpt_answers</th>\n",
       "      <th>cleaned_gpt_ans</th>\n",
       "      <th>cleaned_human_ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why is every book I hear about a \" NY Times # ...</td>\n",
       "      <td>[Basically there are many categories of \" Best...</td>\n",
       "      <td>[There are many different best seller lists th...</td>\n",
       "      <td>__label__AIGenerated different best seller lis...</td>\n",
       "      <td>__label__HumanWritten basically categories bes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If salt is so bad for cars , why do we use it ...</td>\n",
       "      <td>[salt is good for not dying in car crashes and...</td>\n",
       "      <td>[Salt is used on roads to help melt ice and sn...</td>\n",
       "      <td>__label__AIGenerated salt roads help melt ice ...</td>\n",
       "      <td>__label__HumanWritten salt good dying car cras...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do we still have SD TV channels when HD lo...</td>\n",
       "      <td>[The way it works is that old TV stations got ...</td>\n",
       "      <td>[There are a few reasons why we still have SD ...</td>\n",
       "      <td>__label__AIGenerated reasons sd standard defin...</td>\n",
       "      <td>__label__HumanWritten way works old tv station...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why has nobody assassinated Kim Jong - un He i...</td>\n",
       "      <td>[You ca n't just go around assassinating the l...</td>\n",
       "      <td>[It is generally not acceptable or ethical to ...</td>\n",
       "      <td>__label__AIGenerated generally acceptable ethi...</td>\n",
       "      <td>__label__HumanWritten n t assassinating leader...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How was airplane technology able to advance so...</td>\n",
       "      <td>[Wanting to kill the shit out of Germans drive...</td>\n",
       "      <td>[After the Wright Brothers made the first powe...</td>\n",
       "      <td>__label__AIGenerated wright brothers powered f...</td>\n",
       "      <td>__label__HumanWritten wanting kill shit german...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Why is every book I hear about a \" NY Times # ...   \n",
       "1  If salt is so bad for cars , why do we use it ...   \n",
       "2  Why do we still have SD TV channels when HD lo...   \n",
       "3  Why has nobody assassinated Kim Jong - un He i...   \n",
       "4  How was airplane technology able to advance so...   \n",
       "\n",
       "                                       human_answers  \\\n",
       "0  [Basically there are many categories of \" Best...   \n",
       "1  [salt is good for not dying in car crashes and...   \n",
       "2  [The way it works is that old TV stations got ...   \n",
       "3  [You ca n't just go around assassinating the l...   \n",
       "4  [Wanting to kill the shit out of Germans drive...   \n",
       "\n",
       "                                     chatgpt_answers  \\\n",
       "0  [There are many different best seller lists th...   \n",
       "1  [Salt is used on roads to help melt ice and sn...   \n",
       "2  [There are a few reasons why we still have SD ...   \n",
       "3  [It is generally not acceptable or ethical to ...   \n",
       "4  [After the Wright Brothers made the first powe...   \n",
       "\n",
       "                                     cleaned_gpt_ans  \\\n",
       "0  __label__AIGenerated different best seller lis...   \n",
       "1  __label__AIGenerated salt roads help melt ice ...   \n",
       "2  __label__AIGenerated reasons sd standard defin...   \n",
       "3  __label__AIGenerated generally acceptable ethi...   \n",
       "4  __label__AIGenerated wright brothers powered f...   \n",
       "\n",
       "                                   cleaned_human_ans  \n",
       "0  __label__HumanWritten basically categories bes...  \n",
       "1  __label__HumanWritten salt good dying car cras...  \n",
       "2  __label__HumanWritten way works old tv station...  \n",
       "3  __label__HumanWritten n t assassinating leader...  \n",
       "4  __label__HumanWritten wanting kill shit german...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([df[\"cleaned_gpt_ans\"],df[\"cleaned_human_ans\"]], ignore_index=True,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48644,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        __label__AIGenerated different best seller lis...\n",
       "1        __label__AIGenerated salt roads help melt ice ...\n",
       "2        __label__AIGenerated reasons sd standard defin...\n",
       "3        __label__AIGenerated generally acceptable ethi...\n",
       "4        __label__AIGenerated wright brothers powered f...\n",
       "                               ...                        \n",
       "48639    __label__HumanWritten hello welcome thank aski...\n",
       "48640    __label__HumanWritten hi surgical experience i...\n",
       "48641    __label__HumanWritten difficult comment acutre...\n",
       "48642    __label__HumanWritten welcome thank asking hcm...\n",
       "48643    __label__HumanWritten hi having type pain age ...\n",
       "Length: 48644, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"plagarism_check_data.txt\",index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training model on formated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3h 44min 56s\n",
      "Wall time: 21min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#model = fasttext.train_supervised(\"plagarism_check_data.txt\", ws=5, lr=0.05, epoch=50, dim=300, minn=2, maxn=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save model for further application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_model(\"fasttext_plagarism3.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:\\\\Nikhil\\\\VScode\\\\ML\\\\datasets&models\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.load_model(path + \"fasttext_plagarism3.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_word_vector(\"machine\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9921006560325623, 'machines'),\n",
       " (0.9898130893707275, 'machins'),\n",
       " (0.9895593523979187, 'submachine'),\n",
       " (0.9884148836135864, 'machin'),\n",
       " (0.9872796535491943, 'machined'),\n",
       " (0.9854716062545776, 'nmachine'),\n",
       " (0.9853755235671997, 'nanomachines'),\n",
       " (0.9847303628921509, 'nengine'),\n",
       " (0.9846785068511963, 'joachin'),\n",
       " (0.9844298958778381, 'npowerline')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_nearest_neighbors(\"machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(preprocess(\"\"\"ohn left me, and a few minutes later I saw him from my window walking slowly across the grass arm in arm with Cynthia Murdoch. I heard Mrs. Inglethorp call \"Cynthia\" impatiently, and the girl started and ran back to the house.\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__HumanWritten',), array([0.99998307]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    text = preprocess(text)\n",
    "    prediction = model.predict(text)\n",
    "\n",
    "    if prediction[0][0]==\"__label__HumanWritten\":\n",
    "        print(f\"{(100 - prediction[1][0]*100).round(2)}% plagiarism detected\")\n",
    "\n",
    "    else:\n",
    "        print(f\"{(prediction[1][0]*100).round(2)}% plagiarism detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.46% plagiarism detected\n",
      "99.98% plagiarism detected\n"
     ]
    }
   ],
   "source": [
    "human_written = \"The aroma of warm bread and buttery croissants filled the air, pulling Amelia towards the bakery like a magnet. Stepping inside, the cozy atmosphere embraced her. Flour dusted baskets overflowed with golden baguettes, and a chalkboard menu scrawled enticing specials. Amelia's stomach rumbled, and a smile crept across her face. Today, she was indulging.\"\n",
    "AI_generated = \"Bakery X offers a variety of breads and pastries made with fresh, high-quality ingredients. Their menu includes baguettes, croissants, muffins, and more. They also offer a selection of sandwiches and coffee drinks.\"\n",
    "\n",
    "predict(human_written)\n",
    "predict(AI_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.05% plagiarism detected\n"
     ]
    }
   ],
   "source": [
    "predict(\"\"\"\n",
    " 🚀Excited to share my latest project on Plagiarism Detection using NLP! 🚀\n",
    "\n",
    "Over the past three weeks, I've dived deep into Natural Language Processing (NLP) and honed my skills in tools like NLTK, FastText, Gensim, and spaCy. This journey has culminated in the creation of a plagiarism detection system, leveraging word embeddings in Gensim and advanced preprocessing techniques.\n",
    "\n",
    "🔍 Project Highlights:\n",
    "\n",
    "📝Utilized word embeddings in Gensim for accurate text similarity measurement.\n",
    "\n",
    "📝Implemented comprehensive text preprocessing techniques including tokenization, lemmatization, and stop-word removal.\n",
    "\n",
    "📝Integrated multiple NLP tools such as NLTK and spaCy for efficient text processing.\n",
    "\n",
    "This project has not only deepened my understanding of NLP but also opened up new avenues for future exploration.\n",
    "\n",
    "#NLP #MachineLearning #ArtificialIntelligence #PlagiarismDetection #Gensim #NLTK #spaCy #FastText #DataScience #Tech\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
